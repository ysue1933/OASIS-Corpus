
What this research was about and why it is important 
 It is important to be able to identify research results likely to have been arrived at by means of “p-hacking” or “hidden flexibility”, that is, through practices in data collection, data analysis, and reporting of results in quantitative research that are illegitimate because they are biased toward finding a p-value lower than the benchmark value for statistical significance (e.g., benchmark = .05). This paper discusses and demonstrates “p-curving”, which is a method for checking a set of studies for signs of p-hacking. A p-curve analysis can by carried out if a) p-values reported in studies are “independent”―that is, no two studies can be based on responses from the same language learner; b) all of the p-values relate to the same research question; and c) the only studies taken into account are ones that yielded a statistically significant p-value in the direction predicted by the research hypothesis―that is, the results support the research hypothesis. What the researcher did 
● Suppose that a set of good independent studies investigating the same research hypothesis have yielded number of significant p-values (e.g., 20). If the size of the investigated effect is 0, we can expect those p-values to be approximately evenly distributed between 0 and 1. 5% of the p-values are between 0 and .05, 5% are between .05 and .10, and so on right up to 1. If the effect size (ES) is not 0, then the distribution of p-values can be expected to look different. Specifically, the further the ES is from 0, the more the 0 to 1 p-value distribution approaches being L-shaped. The 0 to .05 range will also become approximately L-shaped. 
● If a sizeable fraction of the studies were not good because some of the researchers engaged in p-hacking the shape of the p-curve will look different than expected. If ES ≠ 0, then the distribution of the significant p-values (i.e., the ones below .05) is likely to be somewhat U- or J-shaped. We know what shape a 0 to .05 p-curve should have when there has been no p-hacking. So, if there was p-hacking, analysis of a 0 to .05 p-curve could show this (see Figure 1). Figure 1. This Figure shows two p-curves based on Lakens’s (2018) p-curve analysis of two sets of published studies. The solid line shows the expected rough L-shape, which indicates that the 18 p-values from the first set of studies are consistent with a true effect and are not consistent with noteworthy p-hacking. In contrast, the dashed line shows a rough J-shape, which indicates that a substantial percentage of the 18 p-values in the second set of studies reflect p-hacking. This set of significant p-values does not provide evidence of a true effect. The horizontal dotted line shows the expected p-curve if there was no p-hacking and if ES = 0. Note also that the highest point on the solid line means that 50% of the p-values were ≤ .01 while the lowest point means that about 5% were between p = .04 and p = .05. 
● The paper presents a case study that illustrates how to construct and analyse a p-curve as a complement to meta-analysis. The case study used a set of studies investigating the hypothesis that for low and middle proficiency learners of English L1 glosses facilitate vocabulary learning during reading better than L2 glosses do. The studies all confirmed the hypothesis (p< 0.05). What the researcher found 
● Analysis of the p-curve revealed no signs of p-hacking. This suggests that the set of studies confirming the hypothesis found a true effect. 
Things to consider
 There are several specific reasons why a p-curve analysis might be carried out― for example, (1) to determine which of two sets of contradictory findings is the most credible, (2) to identify studies in a research stream that especially need to be corroborated in a replication study, or (3) to decide which of two tempting research programs is the most likely to lead to results that are credible and publishable. More generally, if SLA researchers routinely carry out p-curve analyses, evidence will finally accumulate about whether or to what extent p-hacking is a problem in SLA quantitative research Reference: Lakens, D. (2018). Professors are not elderly: Evaluating the evidential value of two social priming effects through p-curve analyses. Eindhoven University of Technology. https://psyarxiv.com/3m5y9/ 