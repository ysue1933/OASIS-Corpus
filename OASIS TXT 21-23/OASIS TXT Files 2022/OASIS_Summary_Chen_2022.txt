
What this research was about and why it is important 
 Task complexity, the outcome of attentional, reasoning, and processing demand imposed by tasks on second language (L2) learners’ oral and written production, has been widely studied in the fields of L2 pedagogy and second language acquisition. However, whether the research findings can be applied to language assessment using tasks (e.g., decision making, opinion exchange) and pragmatic language use remains underexplored. This study investigates the impact of task complexity on rapport-building language use and its relationship with paired speaking test scores. Establishing rapport with a speaking partner during paired speaking interactions is crucial because it creates a positive atmosphere that potentially enhances test performance. However, whether such pragmatic use of language is particularly related to L2 speaking performance when an interactive speaking assessment task is cognitively demanding remains underexplored.  What the researcher did 
● 52 intermediate-level English as a Second Language learners (13 pairs for each task) completed a decision-making assessment task with different task complexity levels in pairs as the achievement test in an English for Academic Purposes program. The two tasks differed in causal reasoning demand, number of elements, and pretask planning time.  
● Each pairs’ speaking performance was measured by two raters on three dimensions using an analytic rubric (assign a separate score for each dimension of the test task performance): collaboration (how well learners worked together and responded to each other’s ideas), task completion (the extent to which all the elements of the tasks were addressed) and style (the ability to state an opinion, persuade their partner, and use appropriate expression).  
● Each pairs’ use of rapport-building language (agreeing, seeking agreement, complimenting, thanking, mitigating disagreement, greeting, and closing) was coded and analyzed. What the researcher found 
● The results showed that frequency and variety of rapport-building language use did not differ between the two tasks. 
● Task complexity factors did not lead to an increase in the frequency and types of rapport-building language use for learners working on the complex task. 
● Complexity did influence raters’ judgment of paired speaking test performance and learners’ production of rapport-building language, in terms of alignment with their speaking partners and formality of the words and phrases used. 
● Only in the simple task did different types of rapport-building language have positive or negative relationships with different dimensions of paired speaking test scores: Greeting language use had a strong or close to strong positive relationship with collaboration and style scores, whereas agreeing language had a strong negative relationship with collaboration scores. Additionally, thanking language had a strong negative association with task completion scores. 
Things to consider
 
● The study implies the usefulness of developing assessment rubrics that measure the use of rapport-building language or other pragmatic language use according to different complexity levels of assessment tasks. 
● Using an analytic rubric for achievement tests might be helpful for L2 learners because they can offer learners detailed feedback on their paired speaking test performance.  
● Teachers may want to train learners to use rapport-building language appropriately in paired speaking testing situations and other encounters by teaching learners different kinds of rapport-building language, such as words and phrases on a continuum of style formality that are useful for task completion and aligning with the person they are speaking with. 
● Avenues for future research include using different assessment tasks to operationalize task complexity (e.g., picture narrative, IELTS long-turn task, and TOEFL integrated task), analyzing both verbal and nonverbal cues of rapport building in paired interaction (e.g. gestures, smiles, other facial expressions, and prosodic features), and investigating raters’ scoring processes and strategies through stimulated recalls or interviews.  